import errno
import json
import os

import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import pandas as pd
import scipy.misc
from scipy.ndimage import rotate
from scipy.stats import bernoulli

# Some useful constants
DRIVING_LOG_FILE = './data/test.csv'
IMG_PATH = './'
STEERING_COEFFICIENT = 0.229


def crop(image, top_percent, bottom_percent):
    """
    Crops an image according to the given parameters

    :param image: source image

    :param top_percent:
        The percentage of the original image will be cropped from the top of the image

    :param bottom_percent:
        The percentage of the original image will be cropped from the bottom of the image

    :return:
        The cropped image
    """
    assert 0 <= top_percent < 0.5, 'top_percent should be between 0.0 and 0.5'
    assert 0 <= bottom_percent < 0.5, 'top_percent should be between 0.0 and 0.5'

    top = int(np.ceil(image.shape[0] * top_percent))
    bottom = image.shape[0] - int(np.ceil(image.shape[0] * bottom_percent))

    return image[top:bottom, :]


def resize(image, new_dim):
    """
    Resize a given image according the the new dimension

    :param image:
        Source image

    :param new_dim:
        A tuple which represents the resize dimension

    :return:
        Resize image
    """
    return scipy.misc.imresize(image, new_dim)


def random_flip(image, action, flipping_prob=0.5):
    """
    Based on the outcome of an coin flip, the image will be flipped.
    If flipping is applied, the steering action will be negated.

    :param image: Source image

    :param action: Original steering action

    :return: Both flipped image and new steering action
    """
    head = bernoulli.rvs(flipping_prob)
    if head:
        return np.fliplr(image), -1 * action
    else:
        return image, action


def random_gamma(image):
    """
    Random gamma correction is used as an alternative method changing the brightness of
    training images.
    http://www.pyimagesearch.com/2015/10/05/opencv-gamma-correction/

    :param image:
        Source image

    :return:
        New image generated by applying gamma correction to the source image
    """
    gamma = np.random.uniform(0.4, 1.5)
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255
                      for i in np.arange(0, 256)]).astype("uint8")

    # apply gamma correction using the lookup table
    return cv2.LUT(image, table)


def random_shear(image, action, shear_range=200):
    """
    Source: https://medium.com/@ksakmann/behavioral-cloning-make-a-car-drive-like-yourself-dc6021152713#.7k8vfppvk

    :param image:
        Source image on which the shear operation will be applied

    :param action:
        The steering action of the image

    :param shear_range:
        Random shear between [-shear_range, shear_range + 1] will be applied

    :return:
        The image generated by applying random shear on the source image
    """
    rows, cols, ch = image.shape
    dx = np.random.randint(-shear_range, shear_range + 1)
    random_point = [cols / 2 + dx, rows / 2]
    pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])
    pts2 = np.float32([[0, rows], [cols, rows], random_point])
    dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0
    M = cv2.getAffineTransform(pts1, pts2)
    image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)
    action += dsteering

    return image, action


def random_rotation(image, action, rotation_amount=15):
    """

    :param image:
    :param action:
    :param rotation_amount:
    :return:
    """
    action = np.random.uniform(-rotation_amount, rotation_amount + 1)
    rad = (np.pi / 180.0) * action
    return rotate(image, action, reshape=False), action + (-1) * rad


def min_max(data, a=-0.5, b=0.5):
    """

    :param data:
    :param a:
    :param b:
    :return:
    """
    data_max = np.max(data)
    data_min = np.min(data)
    return a + (b - a) * ((data - data_min) / (data_max - data_min))


def generate_new_image(image, action, top_crop_percent=0.35, bottom_crop_percent=0.1,
                       resize_dim=(64, 64), do_shear_prob=0.9):
    """

    :param image:
    :param action:
    :param top_crop_percent:
    :param bottom_crop_percent:
    :param resize_dim:
    :param do_shear_prob:
    :param shear_range:
    :return:
    """
    # head = bernoulli.rvs(do_shear_prob)
    # if head == 1:
    #    image, action = random_shear(image, action)

    # image = crop(image, top_crop_percent, bottom_crop_percent)

    # image, action = random_flip(image, action)

    #image = random_gamma(image)

    #image = resize(image, resize_dim)

    return image, action


def get_next_image_files(csvFile=DRIVING_LOG_FILE, batch_size=64):
    """
    The simulator records three images (namely: left, center, and right) at a given time
    However, when we are picking images for training we randomly (with equal probability)
    one of these three images and its steering action.

    :param batch_size:
        Size of the image batch

    :return:
        An list of selected (image files names, respective steering actions)
    """
    data = pd.read_csv(csvFile)
    num_of_img = len(data)
    rnd_indices = np.random.randint(0, num_of_img, batch_size)

    image_files_and_actions = []
    for index in rnd_indices:
        img = data.iloc[index]['name'].strip()
        action = data.iloc[index]['action']
        image_files_and_actions.append((img, action))

    return image_files_and_actions

def get_next_image_files_seq(csvFile=DRIVING_LOG_FILE, batch_size=64, g_index=0):
    """
    The simulator records three images (namely: left, center, and right) at a given time
    However, when we are picking images for training we randomly (with equal probability)
    one of these three images and its steering action.

    :param batch_size:
        Size of the image batch

    :return:
        An list of selected (image files names, respective steering actions)
    """
    data = pd.read_csv(csvFile)
    num_of_img = len(data)
    start = g_index
    end = g_index + batch_size
    if end >= num_of_img:
        end = num_of_img

    index = 0;

    image_files_and_actions = []
    while index < batch_size:
        if (start+index) < end:
            img = data.iloc[start+index]['name'].strip()
            action = data.iloc[start+index]['action']
        else:
            img = data.iloc[index]['name'].strip()
            action = data.iloc[index]['action']    
        image_files_and_actions.append((img, action))
        index += 1

    return image_files_and_actions

def generate_next_batch(batch_size=64):
    g_index = 0
    g_data = pd.read_csv(DRIVING_LOG_FILE)
    g_num_of_img = len(g_data)

    """
    This generator yields the next training batch

    :param batch_size:
        Number of training images in a single batch

    :return:
        A tuple of features and steering actions as two numpy arrays
    """
    while True:
        X_batch = []
        y_batch = []
        images = get_next_image_files_seq(DRIVING_LOG_FILE, batch_size, g_index)

        g_index += batch_size
        if g_index >= g_num_of_img:
            g_index = 0

        for img_file, action in images:
            raw_image = plt.imread(IMG_PATH+img_file)
            raw_action = action
            new_image, new_action = generate_new_image(raw_image, raw_action)
            X_batch.append(new_image)
            y_batch.append(new_action)

        assert len(
            X_batch) == batch_size, 'len(X_batch) == batch_size should be True'

        yield np.array(X_batch), np.array(y_batch)

def generate_next_validate_batch(filename, batch_size=64, one_hot=False, n_class=1):
    g_index = 0
    g_data = pd.read_csv(filename)
    g_num_of_img = len(g_data)

    """
    This generator yields the next training batch

    :param batch_size:
        Number of training images in a single batch

    :return:
        A tuple of features and steering actions as two numpy arrays
    """
    while True:
        X_batch = []
        y_batch = []
        images = get_next_image_files_seq(filename, batch_size, g_index)

        g_index += batch_size
        if g_index >= g_num_of_img:
            g_index = 0

        for img_file, action in images:
            raw_image = plt.imread(IMG_PATH+img_file)
            raw_action = action
            new_image, new_action = generate_new_image(raw_image, raw_action)

            if one_hot and n_class:
                label = tf.one_hot(new_action, n_class)
            else :
                label = new_action    

            X_batch.append(new_image)
            y_batch.append(label)

        assert len(
            X_batch) == batch_size, 'len(X_batch) == batch_size should be True'

        yield np.array(X_batch), np.array(y_batch)        


def save_model(model, model_name='model.json', weights_name='model.h5'):
    """
    Save the model into the hard disk

    :param model:
        Keras model to be saved

    :param model_name:
        The name of the model file

    :param weights_name:
        The name of the weight file

    :return:
        None
    """
    silent_delete(model_name)
    silent_delete(weights_name)

    json_string = model.to_json()
    with open(model_name, 'w') as outfile:
        json.dump(json_string, outfile)

    model.save_weights(weights_name)


def silent_delete(file):
    """
    This method delete the given file from the file system if it is available
    Source: http://stackoverflow.com/questions/10840533/most-pythonic-way-to-delete-a-file-which-may-not-exist

    :param file:
        File to be deleted

    :return:
        None
    """
    try:
        os.remove(file)

    except OSError as error:
        if error.errno != errno.ENOENT:
            raise

def GetTFRecords(tfrecords):
    files = tf.train.match_filenames_once(tfrecords)
    filename_queue = tf.train.string_input_producer(files, shuffle=False)
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
            serialized_example,
            features = {
                    'height': tf.FixedLenFeature([], tf.int64),
                    'width': tf.FixedLenFeature([], tf.int64),
                    'depth': tf.FixedLenFeature([], tf.int64),
                    'image_raw': tf.FixedLenFeature([], tf.string),
                    'label':tf.FixedLenFeature([], tf.int64)})
    return features

def GetBatchImageAndLabel(tfrecords, rows, cols, depth, batch_size):
    MIN_DEQ     = 20000
    CAPACITY    = MIN_DEQ + 3 * batch_size

    train_features = GetTFRecords(tfrecords)
    samples = train_features['image_raw']
    decoded_images  = tf.decode_raw(samples, tf.uint8)
    retyped_images = tf.image.convert_image_dtype(decoded_images, dtype = tf.float32)
    labels  = tf.cast(train_features['label'], tf.int64)
    images  = tf.reshape(retyped_images, [rows, cols, depth])

    data1 = [images, labels]
    print (data1)

    batch_images, batch_labels = tf.train.batch(
            tensors = data1, 
            batch_size = batch_size, 
            capacity = CAPACITY,
            num_threads = 8)
    return batch_images, batch_labels       

if __name__ == '__main__':
    generate_next_batch(64)
